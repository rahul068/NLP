{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1b59bbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, CuDNNLSTM, LSTM, SpatialDropout1D, GlobalMaxPool1D, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.utils import resample\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import string   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a82bf2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./fake-news/train.csv', delimiter=\",\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7a0cce91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Jessica Purkiss</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Howard Portnoy</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title              author  \\\n",
       "0   0  House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n",
       "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
       "2   2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n",
       "3   3  15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n",
       "4   4  Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n",
       "\n",
       "                                                text  label  \n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
       "1  Ever get the feeling your life circles the rou...      0  \n",
       "2  Why the Truth Might Get You Fired October 29, ...      1  \n",
       "3  Videos 15 Civilians Killed In Single US Airstr...      1  \n",
       "4  Print \\nAn Iranian woman has been sentenced to...      1  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d05fb0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['author'] + \" \" + data['title'] + \" \" +  data['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f48d0d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-49-7487443a8a60>:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  data = data.drop(['id','title','author'],1)\n"
     ]
    }
   ],
   "source": [
    "data = data.drop(['id','title','author'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f636be03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import List\n",
    "\n",
    "import spacy\n",
    "from spacy.tokens import Doc\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class SpacyPreprocessor:\n",
    "    def __init__(\n",
    "        self,\n",
    "        spacy_model=None,\n",
    "        remove_numbers=False,\n",
    "        remove_special=True,\n",
    "        pos_to_remove=None,\n",
    "        remove_stopwords=False,\n",
    "        lemmatize=False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Preprocesses text using spaCy\n",
    "        :param remove_numbers: Whether to remove numbers from text\n",
    "        :param remove_stopwords: Whether to remove stopwords from text\n",
    "        :param remove_special: Whether to remove special characters (including numbers)\n",
    "        :param pos_to_remove: list of PoS tags to remove\n",
    "        :param lemmatize:  Whether to apply lemmatization\n",
    "        \"\"\"\n",
    "\n",
    "        self._remove_numbers = remove_numbers\n",
    "        self._pos_to_remove = pos_to_remove\n",
    "        self._remove_stopwords = remove_stopwords\n",
    "        self._remove_special = remove_special\n",
    "        self._lemmatize = lemmatize\n",
    "\n",
    "        if not spacy_model:\n",
    "            self.model = spacy.load(\"en_core_web_sm\")\n",
    "        else:\n",
    "            self.model = spacy_model\n",
    "\n",
    "    @staticmethod\n",
    "    def download_spacy_model(model=\"en_core_web_sm\"):\n",
    "        print(f\"Downloading spaCy model {model}\")\n",
    "        spacy.cli.download(model)\n",
    "        print(f\"Finished downloading model\")\n",
    "\n",
    "    @staticmethod\n",
    "    def load_model(model=\"en_core_web_sm\"):\n",
    "        return spacy.load(model, disable=[\"ner\", \"parser\"])\n",
    "\n",
    "    def tokenize(self, text) -> List[str]:\n",
    "        \"\"\"\n",
    "        Tokenize text using a spaCy pipeline\n",
    "        :param text: Text to tokenize\n",
    "        :return: list of str\n",
    "        \"\"\"\n",
    "        doc = self.model(text)\n",
    "        return [token.text for token in doc]\n",
    "\n",
    "    def preprocess_text(self, text) -> str:\n",
    "        \"\"\"\n",
    "        Runs a spaCy pipeline and removes unwanted parts from text\n",
    "        :param text: text string to clean\n",
    "        :return: str, clean text\n",
    "        \"\"\"\n",
    "        doc = self.model(text)\n",
    "        return self.__clean(doc)\n",
    "\n",
    "    def preprocess_text_list(self, texts=List[str]) -> List[str]:\n",
    "        \"\"\"\n",
    "        Runs a spaCy pipeline and removes unwantes parts from a list of text.\n",
    "        Leverages spaCy's `pipe` for faster batch processing.\n",
    "        :param texts: List of texts to clean\n",
    "        :return: List of clean texts\n",
    "        \"\"\"\n",
    "        clean_texts = []\n",
    "        for doc in tqdm(self.model.pipe(texts)):\n",
    "            clean_texts.append(self.__clean(doc))\n",
    "\n",
    "        return clean_texts\n",
    "\n",
    "    def __clean(self, doc: Doc) -> str:\n",
    "\n",
    "        tokens = []\n",
    "        # POS Tags removal\n",
    "        if self._pos_to_remove:\n",
    "            for token in doc:\n",
    "                if token.pos_ not in self._pos_to_remove:\n",
    "                    tokens.append(token)\n",
    "        else:\n",
    "            tokens = doc\n",
    "\n",
    "        # Remove Numbers\n",
    "        if self._remove_numbers:\n",
    "            tokens = [\n",
    "                token for token in tokens if not (token.like_num or token.is_currency)\n",
    "            ]\n",
    "\n",
    "        # Remove Stopwords\n",
    "        if self._remove_stopwords:\n",
    "            tokens = [token for token in tokens if not token.is_stop]\n",
    "        # remove unwanted tokens\n",
    "        tokens = [\n",
    "            token\n",
    "            for token in tokens\n",
    "            if not (\n",
    "                token.is_punct or token.is_space or token.is_quote or token.is_bracket\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        # Remove empty tokens\n",
    "        tokens = [token for token in tokens if token.text.strip() != \"\"]\n",
    "\n",
    "        # Lemmatize\n",
    "        if self._lemmatize:\n",
    "            text = \" \".join([token.lemma_ for token in tokens])\n",
    "        else:\n",
    "            text = \" \".join([token.text for token in tokens])\n",
    "\n",
    "        if self._remove_special:\n",
    "            # Remove non alphabetic characters\n",
    "            text = re.sub(r\"[^a-zA-Z\\']\", \" \", text)\n",
    "        # remove non-Unicode characters\n",
    "        text = re.sub(r\"[^\\x00-\\x7F]+\", \"\", text)\n",
    "\n",
    "        text = text.lower()\n",
    "\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b46ab763",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = SpacyPreprocessor(remove_numbers=True,\n",
    "                                 remove_special=True,\n",
    "#                                 pos_to_remove=True,\n",
    "                                 remove_stopwords=True,\n",
    "                                 lemmatize=True)\n",
    "data['text'] = data['text'].apply(lambda x: preprocessor.preprocess_text(str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "be81cb5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>darrell lucus house dem aide we didn’t even se...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>daniel j flynn flynn hillary clinton big woman...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>consortiumnewscom why the truth might get you ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jessica purkiss  civilians killed in single us...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>howard portnoy iranian woman jailed for fictio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  darrell lucus house dem aide we didn’t even se...      1\n",
       "1  daniel j flynn flynn hillary clinton big woman...      0\n",
       "2  consortiumnewscom why the truth might get you ...      1\n",
       "3  jessica purkiss  civilians killed in single us...      1\n",
       "4  howard portnoy iranian woman jailed for fictio...      1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dafcc069",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = set(\" \".join(data['text'].tolist()).split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0a36ccce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'',\n",
       " 'substitute',\n",
       " 'maxwel',\n",
       " 'lutein',\n",
       " 'falla',\n",
       " 'cratchette',\n",
       " 'wenezuel',\n",
       " 'polaroid',\n",
       " 'whyatt',\n",
       " 'shyer',\n",
       " 'votetoday',\n",
       " 'creativo',\n",
       " 'serlo',\n",
       " 'iaf',\n",
       " 'kaffiyeh',\n",
       " 'overtreatment',\n",
       " 'nonstick',\n",
       " 'mpft',\n",
       " 'fram',\n",
       " 'hajaja',\n",
       " 'multicity',\n",
       " 'frontal',\n",
       " 'purine',\n",
       " 'exsactly',\n",
       " 'portraitist',\n",
       " 'lomonte',\n",
       " 'venusino',\n",
       " 'insolvent',\n",
       " 'hockenbury',\n",
       " 'madiran',\n",
       " 'conducir',\n",
       " 'uncontested',\n",
       " 'amerisleep',\n",
       " 'ndeme',\n",
       " 'gallagher',\n",
       " 'iaayh',\n",
       " 'forfeits',\n",
       " 'niebla',\n",
       " 'palumbo',\n",
       " 'talker',\n",
       " 'patronal',\n",
       " 'rottentomatoes',\n",
       " 'hamlyn',\n",
       " 'thirdworldize',\n",
       " 'masshole',\n",
       " 'enministeriums',\n",
       " 'offrir',\n",
       " 'obliterate',\n",
       " 'kissinger',\n",
       " 'injun',\n",
       " 'unhealthy',\n",
       " 'shishapangma',\n",
       " 'bijan',\n",
       " 'jamshoro',\n",
       " 'precipitant',\n",
       " 'johannsson',\n",
       " 'berankis',\n",
       " 'euler',\n",
       " 'wissen',\n",
       " 'longo',\n",
       " 'decolonization',\n",
       " 'poaching',\n",
       " 'aliquippa',\n",
       " 'bonquita',\n",
       " 'yousefi',\n",
       " 'llevado',\n",
       " 'greenwave',\n",
       " 'nullification',\n",
       " 'inventer',\n",
       " 'swinging',\n",
       " 'politicizing',\n",
       " 'lauric',\n",
       " 'ld',\n",
       " 'pretentiously',\n",
       " 'terawatt',\n",
       " 'emidio',\n",
       " 'anbd',\n",
       " 'events',\n",
       " 'loch',\n",
       " 'marjorie',\n",
       " 'croaky',\n",
       " 'perspiring',\n",
       " 'voortkoman',\n",
       " 'superinsulated',\n",
       " 'pty',\n",
       " 'bislang',\n",
       " 'abovetopsecret',\n",
       " 'staver',\n",
       " 'staus',\n",
       " 'pookie',\n",
       " 'asawin',\n",
       " 'salesroom',\n",
       " 'clapham',\n",
       " 'abhijit',\n",
       " 'pocz',\n",
       " 'suppression',\n",
       " 'hancock',\n",
       " 'tarjeta',\n",
       " 'chica',\n",
       " 'gurkan',\n",
       " 'workaround',\n",
       " 'astringent',\n",
       " 'lagomarsino',\n",
       " 'heroization',\n",
       " 'sich',\n",
       " 'schimelpfenig',\n",
       " 'tto',\n",
       " 'dontre',\n",
       " 'intermarium',\n",
       " 'ward',\n",
       " 'weegens',\n",
       " 'ikhtilat',\n",
       " 'shaffer',\n",
       " 'irons',\n",
       " 'tami',\n",
       " 'metaphorically',\n",
       " 'obscurantism',\n",
       " 'coralie',\n",
       " 'zahlreiche',\n",
       " 'circumpolar',\n",
       " 'edda',\n",
       " 'actuara',\n",
       " 'breasts',\n",
       " 'gebbia',\n",
       " 'modulating',\n",
       " 'statesmanlike',\n",
       " 'anomalousness',\n",
       " 'denigrante',\n",
       " 'shamma',\n",
       " 'kristopher',\n",
       " 'noman',\n",
       " 'fluke',\n",
       " 'scythians',\n",
       " 'precipitate',\n",
       " 'ethical',\n",
       " 'filmfare',\n",
       " 'redaktionsassistentin',\n",
       " 'everythe',\n",
       " 'olmayan',\n",
       " 'roguemoney',\n",
       " 'eccentric',\n",
       " 'zinedine',\n",
       " 'elsene',\n",
       " 'legalexaminer',\n",
       " 'exports',\n",
       " 'megabit',\n",
       " 'search',\n",
       " 'treasurer',\n",
       " 'calmer',\n",
       " 'draplin',\n",
       " 'victimization',\n",
       " 'jak',\n",
       " 'reignofapril',\n",
       " 'sounio',\n",
       " 'muhaysini',\n",
       " 'lors',\n",
       " 'ome',\n",
       " 'hep',\n",
       " 'walshfreedom',\n",
       " 'lkdi',\n",
       " 'lisum',\n",
       " 'misallocate',\n",
       " 'wessler',\n",
       " 'broiles',\n",
       " 'arranca',\n",
       " 'fia',\n",
       " 'kallstadt',\n",
       " 'spector',\n",
       " 'santamar',\n",
       " 'picnicker',\n",
       " 'twila',\n",
       " 'abalone',\n",
       " 'vitando',\n",
       " 'statewide',\n",
       " 'einfach',\n",
       " 'sakwa',\n",
       " 'ippolito',\n",
       " 'mondello',\n",
       " 'grasslike',\n",
       " 'grier',\n",
       " 'funches',\n",
       " 'seige',\n",
       " 'sarcoma',\n",
       " 'overrepresentation',\n",
       " 'luis',\n",
       " 'scottish',\n",
       " 'lurching',\n",
       " 'satin',\n",
       " 'tolson',\n",
       " 'ho',\n",
       " 'georgetakei',\n",
       " 'agricol',\n",
       " 'eurekalert',\n",
       " 'carraway',\n",
       " 'vigilantly',\n",
       " 'hajiya',\n",
       " 'alder',\n",
       " 'declararla',\n",
       " 'millonaria',\n",
       " 'ricochet',\n",
       " 'lackadaisical',\n",
       " 'dull',\n",
       " 'ordon',\n",
       " 'recycle',\n",
       " 'ingestion',\n",
       " 'kimche',\n",
       " 'metroidvania',\n",
       " 'wiatu',\n",
       " 'grindstone',\n",
       " 'cita',\n",
       " 'xpyzbdn',\n",
       " 'afirm',\n",
       " 'sekizinci',\n",
       " 'monday',\n",
       " 'izmir',\n",
       " 'commercialise',\n",
       " 'bedier',\n",
       " 'malty',\n",
       " 'changey',\n",
       " 'masala',\n",
       " 'konomisk',\n",
       " 'trumppence',\n",
       " 'offends',\n",
       " 'gacy',\n",
       " 'poul',\n",
       " 'medinah',\n",
       " 'brinker',\n",
       " 'adivina',\n",
       " 'winters',\n",
       " 'debunk',\n",
       " 'ohanka',\n",
       " 'resueltamente',\n",
       " 'bhushan',\n",
       " 'miembro',\n",
       " 'brav',\n",
       " 'brandonmond',\n",
       " 'inton',\n",
       " 'githyp',\n",
       " 'countrys',\n",
       " 'hamburguesa',\n",
       " 'smartmetereducationnetwork',\n",
       " 'breathtakingly',\n",
       " 'plainest',\n",
       " 'implementarla',\n",
       " 'vehicles',\n",
       " 'ldl',\n",
       " 'worldly',\n",
       " 'lingerie',\n",
       " 'sickest',\n",
       " 'conformar',\n",
       " 'reasonably',\n",
       " 'ovitz',\n",
       " 'girlishness',\n",
       " 'haly',\n",
       " 'irme',\n",
       " 'cuelga',\n",
       " 'hardball',\n",
       " 'nicho',\n",
       " 'lucroy',\n",
       " 'enhancing',\n",
       " 'exuma',\n",
       " 'ioulia',\n",
       " 'villalobos',\n",
       " 'skovorodino',\n",
       " 'muhlig',\n",
       " 'dissociative',\n",
       " 'brandet',\n",
       " 'dialogue',\n",
       " 'spitze',\n",
       " 'pgen',\n",
       " 'heuchelei',\n",
       " 'reaksjon',\n",
       " 'renews',\n",
       " 'avangrid',\n",
       " 'solemnity',\n",
       " 'musk',\n",
       " 'directionless',\n",
       " 'burkha',\n",
       " 'kaust',\n",
       " 'declaration',\n",
       " 'versatility',\n",
       " 'hackism',\n",
       " 'friar',\n",
       " 'policeman',\n",
       " 'backslid',\n",
       " 'squeeze',\n",
       " 'jlr',\n",
       " 'palace',\n",
       " 'precursor',\n",
       " 'hamiltonian',\n",
       " 'ggas',\n",
       " 'prednisone',\n",
       " 'medipen',\n",
       " 'norrmalmstorg',\n",
       " 'aldon',\n",
       " 'pflicht',\n",
       " 'memorizing',\n",
       " 'mutli',\n",
       " 'timed',\n",
       " 'enstupidation',\n",
       " 'the',\n",
       " 'beziers',\n",
       " 'demonetize',\n",
       " 'impassive',\n",
       " 'worauf',\n",
       " 'shafir',\n",
       " 'stanislav',\n",
       " 'populated',\n",
       " 'gibbons',\n",
       " 'sangatte',\n",
       " 'macallah',\n",
       " 'sitios',\n",
       " 'bilmes',\n",
       " 'storyk',\n",
       " 'shangh',\n",
       " 'montinore',\n",
       " 'calving',\n",
       " 'bartella',\n",
       " 'pernicious',\n",
       " 'threat',\n",
       " 'wring',\n",
       " 'devante',\n",
       " 'drezen',\n",
       " 'redstatewatcher',\n",
       " 'unerh',\n",
       " 'lovett',\n",
       " 'perd',\n",
       " 'erda',\n",
       " 'calatrava',\n",
       " 'lister',\n",
       " 'oversize',\n",
       " 'azes',\n",
       " \"s'il\",\n",
       " 'cypress',\n",
       " 'moweek',\n",
       " 'wilw',\n",
       " 'carriedbygrace',\n",
       " 'damon',\n",
       " 'eversole',\n",
       " 'leblanc',\n",
       " 'lilia',\n",
       " 'flock',\n",
       " 'pensioner',\n",
       " 'forgave',\n",
       " 'jackiedstrause',\n",
       " 'midlevel',\n",
       " 'whippoorwills',\n",
       " 'spratt',\n",
       " 'coders',\n",
       " 'perquisite',\n",
       " 'lendi',\n",
       " 'nyjusticeleague',\n",
       " 'elysian',\n",
       " 'pepe',\n",
       " 'dreary',\n",
       " 'kapur',\n",
       " 'abgebildet',\n",
       " 'teniendo',\n",
       " 'fyodor',\n",
       " 'remedial',\n",
       " 'mergens',\n",
       " 'realistas',\n",
       " 'rambourg',\n",
       " 'prioritaria',\n",
       " 'martian',\n",
       " 'raban',\n",
       " 'obersten',\n",
       " 'joanr',\n",
       " 'billion',\n",
       " 'ezzat',\n",
       " 'deviance',\n",
       " 'cinsiyetine',\n",
       " 'mathies',\n",
       " 'tashfeen',\n",
       " 'aaluijqn',\n",
       " 'doke',\n",
       " 'revocable',\n",
       " 'kissito',\n",
       " 'krajnc',\n",
       " 'fortalde',\n",
       " 'freaks',\n",
       " 'tyee',\n",
       " 'transitions',\n",
       " 'euskal',\n",
       " 'dritte',\n",
       " \"n'a\",\n",
       " 'southeast',\n",
       " 'nichtstaatlichen',\n",
       " 'lesquels',\n",
       " 'infestations',\n",
       " 'rapidement',\n",
       " 'wizened',\n",
       " 'overperforme',\n",
       " 'tortuously',\n",
       " 'leisten',\n",
       " 'havegunwilltravel',\n",
       " 'marvellous',\n",
       " 'horia',\n",
       " 'tephi',\n",
       " 'anticonvulsant',\n",
       " 'illegalmente',\n",
       " 'transici',\n",
       " 'thoughtless',\n",
       " 'ching',\n",
       " 'sumlin',\n",
       " 'histrionic',\n",
       " 'sipher',\n",
       " 'sabril',\n",
       " 'subversiveness',\n",
       " 'impregnate',\n",
       " 'skanky',\n",
       " 'fernham',\n",
       " 'bewijs',\n",
       " 'compounds',\n",
       " 'applicant',\n",
       " 'darkostojanovic',\n",
       " 'pasa',\n",
       " 'occupancy',\n",
       " 'annalyn',\n",
       " 'conspire',\n",
       " 'fdr',\n",
       " 'colegir',\n",
       " 'passaic',\n",
       " 'cobain',\n",
       " 'mousse',\n",
       " 'brassage',\n",
       " 'hamam',\n",
       " 'alonzo',\n",
       " 'outdoorsy',\n",
       " 'ebbs',\n",
       " 'annuity',\n",
       " 'goucher',\n",
       " 'medea',\n",
       " 'nathanial',\n",
       " 'vilify',\n",
       " 'crapified',\n",
       " 'ames',\n",
       " 'mankiw',\n",
       " 'induce',\n",
       " 'peccadillo',\n",
       " 'syrians',\n",
       " 'klean',\n",
       " 'trust',\n",
       " 'haag',\n",
       " 'lograr',\n",
       " 'monclova',\n",
       " 'kanl',\n",
       " 'punctuation',\n",
       " 'judd',\n",
       " 'gaudet',\n",
       " 'wuthering',\n",
       " 'kawartha',\n",
       " 'glittering',\n",
       " 'typewriter',\n",
       " 'cordon',\n",
       " 'opone',\n",
       " 'araba',\n",
       " 'quasimodo',\n",
       " 'rennen',\n",
       " 'assumedly',\n",
       " 'ghat',\n",
       " 'voshell',\n",
       " 'implicaci',\n",
       " 'provenance',\n",
       " 'beauts',\n",
       " 'ersoy',\n",
       " 'klausner',\n",
       " 'overreact',\n",
       " 'depart',\n",
       " 'bruhl',\n",
       " 'lessing',\n",
       " 'ngp',\n",
       " 'enforcement',\n",
       " 'bandwagon',\n",
       " 'creepiness',\n",
       " 'zhukova',\n",
       " 'merklichen',\n",
       " 'administered',\n",
       " 'discreetness',\n",
       " 'killion',\n",
       " 'proficiency',\n",
       " 'abendessen',\n",
       " 'visualizer',\n",
       " 'hanya',\n",
       " 'orthodoxen',\n",
       " 'subtweet',\n",
       " 'forcejea',\n",
       " 'kevlar',\n",
       " 'janas',\n",
       " 'disinfo',\n",
       " 'broadness',\n",
       " 'burgaud',\n",
       " 'pulpiteering',\n",
       " 'schwachen',\n",
       " 'hush',\n",
       " 'utilizaci',\n",
       " 'matzu',\n",
       " 'subjectivism',\n",
       " 'austenalia',\n",
       " 'mujhe',\n",
       " 'msh',\n",
       " 'coraz',\n",
       " 'incredibility',\n",
       " 'raiders',\n",
       " 'sluts',\n",
       " 'mandino',\n",
       " 'amtrak',\n",
       " 'wemeantwell',\n",
       " 'erupcj',\n",
       " 'plaything',\n",
       " 'gastonguay',\n",
       " 'reptile',\n",
       " 'precisamente',\n",
       " 'enthronization',\n",
       " 'beauftragen',\n",
       " 'conspiracionista',\n",
       " 'bamboozled',\n",
       " 'aberration',\n",
       " 'condone',\n",
       " 'proposici',\n",
       " 'polish',\n",
       " 'jansson',\n",
       " 'wheeze',\n",
       " 'generalistic',\n",
       " 'perp',\n",
       " 'dahlkvist',\n",
       " 'thirdly',\n",
       " 'muladhara',\n",
       " 'barr',\n",
       " 'rerecorded',\n",
       " 'harekete',\n",
       " 'sportsfunhouse',\n",
       " 'whitewashed',\n",
       " 'ghadir',\n",
       " 'oahe',\n",
       " 'firebombs',\n",
       " 'unfinished',\n",
       " 'deirdre',\n",
       " 'sslich',\n",
       " 'tamler',\n",
       " 'tomllamasabc',\n",
       " 'penalize',\n",
       " 'farag',\n",
       " 'infrastrucutre',\n",
       " 'reckless',\n",
       " 'highbridge',\n",
       " 'muffle',\n",
       " 'curtin',\n",
       " 'roseanne',\n",
       " 'strata',\n",
       " 'berniecrats',\n",
       " 'nuked',\n",
       " 'dumb',\n",
       " 'notable',\n",
       " 'kilimnik',\n",
       " 'casoria',\n",
       " 'turkovich',\n",
       " 'huskey',\n",
       " 'karic',\n",
       " 'wirtschafts',\n",
       " 'pasarme',\n",
       " 'balen',\n",
       " 'minuteness',\n",
       " 'bicarbonate',\n",
       " 'tirer',\n",
       " 'responderle',\n",
       " 'theatlantic',\n",
       " 'oloroso',\n",
       " 'dales',\n",
       " 'xbfyqooo',\n",
       " 'zosia',\n",
       " 'scholarly',\n",
       " 'cpzochyhsvgppzyh',\n",
       " 'sajmir',\n",
       " 'ganyata',\n",
       " 'dysregulate',\n",
       " 'fontanella',\n",
       " 'samimi',\n",
       " 'schlagkr',\n",
       " 'superhuman',\n",
       " 'jamieleecurtis',\n",
       " 'encouraged',\n",
       " 'steele',\n",
       " 'jawetz',\n",
       " 'cekic',\n",
       " 'allegations',\n",
       " 'ludzi',\n",
       " 'comp',\n",
       " 'ukie',\n",
       " 'munn',\n",
       " 'jzws',\n",
       " 'urinate',\n",
       " 'revengeance',\n",
       " 'cowy',\n",
       " 'moiseyev',\n",
       " 'comunidades',\n",
       " 'dvorkovich',\n",
       " 'deliberations',\n",
       " 'peri',\n",
       " 'thresholds',\n",
       " 'voll',\n",
       " 'morphology',\n",
       " 'doctorate',\n",
       " 'nonmetallic',\n",
       " 'epictetus',\n",
       " 'guggenheim',\n",
       " 'fissure',\n",
       " 'acting',\n",
       " 'tuckman',\n",
       " 'sedasso',\n",
       " 'historischer',\n",
       " 'mullainathan',\n",
       " 'mathematically',\n",
       " 'unrelievedly',\n",
       " 'syl',\n",
       " 'allende',\n",
       " 'engelleri',\n",
       " 'sandstrom',\n",
       " 'secessionary',\n",
       " 'gracious',\n",
       " 'majorna',\n",
       " 'hiiumaa',\n",
       " 'aikido',\n",
       " 'possibilmente',\n",
       " 'iliad',\n",
       " 'disgusto',\n",
       " 'churchyard',\n",
       " 'joze',\n",
       " 'rompi',\n",
       " 'mam',\n",
       " 'katko',\n",
       " 'deniega',\n",
       " 'bargain',\n",
       " 'quittner',\n",
       " 'forbiddingly',\n",
       " 'footsoldier',\n",
       " 'ethnocentric',\n",
       " 'expireddomains',\n",
       " 'caffeine',\n",
       " 'shitshow',\n",
       " 'hil',\n",
       " 'uzakla',\n",
       " 'insatiable',\n",
       " 'anapali',\n",
       " 'crystalize',\n",
       " 'inches',\n",
       " 'staatlichen',\n",
       " 'karachay',\n",
       " 'eilperin',\n",
       " 'cheesemaker',\n",
       " 'evac',\n",
       " 'compromised',\n",
       " 'kodaka',\n",
       " 'knoller',\n",
       " 'evitarle',\n",
       " 'partiality',\n",
       " 'wahdat',\n",
       " 'patronato',\n",
       " 'boob',\n",
       " 'louima',\n",
       " 'corgi',\n",
       " 'rbi',\n",
       " 'interestings',\n",
       " 'pare',\n",
       " 'trieu',\n",
       " 'medscape',\n",
       " 'liberdade',\n",
       " 'toddyo',\n",
       " 'cultist',\n",
       " 'unsettling',\n",
       " 'corinne',\n",
       " 'organiserte',\n",
       " 'noreste',\n",
       " 'rori',\n",
       " 'gyory',\n",
       " 'argetsinger',\n",
       " 'socialista',\n",
       " 'grabber',\n",
       " 'mallory',\n",
       " 'creature',\n",
       " 'intune',\n",
       " 'relman',\n",
       " 'rner',\n",
       " 'kramerbooks',\n",
       " 'giles',\n",
       " 'shawn',\n",
       " 'hellish',\n",
       " 'meddling',\n",
       " 'gloe',\n",
       " 'generalizado',\n",
       " 'minim',\n",
       " 'predicate',\n",
       " 'skatell',\n",
       " 'pilotless',\n",
       " 'zuckerman',\n",
       " 'commodities',\n",
       " 'vamc',\n",
       " 'wiecznej',\n",
       " 'fpreventdisease',\n",
       " 'debuff',\n",
       " 'jahweh',\n",
       " 'zang',\n",
       " 'jericho',\n",
       " 'lausd',\n",
       " 'senegal',\n",
       " 'gerrick',\n",
       " 'humanitaire',\n",
       " 'solden',\n",
       " 'denominate',\n",
       " 'turkman',\n",
       " 'dizzying',\n",
       " 'cigarrillos',\n",
       " 'caucusing',\n",
       " 'ferreira',\n",
       " 'nipper',\n",
       " 'exec',\n",
       " 'baha',\n",
       " 'shamima',\n",
       " 'nitzan',\n",
       " 'dimicco',\n",
       " 'serbian',\n",
       " 'truthseeker',\n",
       " 'rightwing',\n",
       " 'ismayilova',\n",
       " 'flushing',\n",
       " 'asme',\n",
       " 'erupt',\n",
       " 'guzzler',\n",
       " 'creyeran',\n",
       " 'cnnpr',\n",
       " 'malmstr',\n",
       " 'transience',\n",
       " 'sunroofs',\n",
       " 'shives',\n",
       " 'labaton',\n",
       " 'pommard',\n",
       " 'beschlagnahmte',\n",
       " 'colectiva',\n",
       " 'anthonyfreda',\n",
       " 'annually',\n",
       " 'restricting',\n",
       " 'supercomputer',\n",
       " 'foodie',\n",
       " 'decosmo',\n",
       " 'gasser',\n",
       " 'matur',\n",
       " 'quadcopter',\n",
       " 'jg',\n",
       " 'ores',\n",
       " 'avelar',\n",
       " 'tayanj',\n",
       " 'magnier',\n",
       " 'faturechi',\n",
       " 'undertegnet',\n",
       " 'monets',\n",
       " 'acrimony',\n",
       " 'deprogramed',\n",
       " 'physiognomy',\n",
       " 'certificado',\n",
       " 'wrangling',\n",
       " 'selvi',\n",
       " 'ravenal',\n",
       " 'induced',\n",
       " 'turbocharged',\n",
       " 'nazaire',\n",
       " 'garroutte',\n",
       " 'kole',\n",
       " 'bondmageddon',\n",
       " 'labelling',\n",
       " 'tumbledown',\n",
       " 'caba',\n",
       " 'dun',\n",
       " 'acelam',\n",
       " 'zytsov',\n",
       " 'nube',\n",
       " 'dfa',\n",
       " 'labin',\n",
       " 'mgs',\n",
       " 'marsay',\n",
       " 'mexifornia',\n",
       " 'falsificaci',\n",
       " 'agobiante',\n",
       " 'metodistas',\n",
       " 'wattsupwiththat',\n",
       " 'steamy',\n",
       " 'vanishes',\n",
       " 'ripulito',\n",
       " 'tained',\n",
       " 'birka',\n",
       " 'doorway',\n",
       " 'kemble',\n",
       " 'nombres',\n",
       " 'jeffkbell',\n",
       " 'embroil',\n",
       " 'plangent',\n",
       " 'nestazhe',\n",
       " 'activation',\n",
       " 'talton',\n",
       " 'alec',\n",
       " 'automakers',\n",
       " 'gorky',\n",
       " 'proofread',\n",
       " 'cour',\n",
       " 'carvacrol',\n",
       " 'trovati',\n",
       " 'plepler',\n",
       " 'ruoff',\n",
       " 'normalness',\n",
       " 'activating',\n",
       " 'immolation',\n",
       " 'golota',\n",
       " 'acx',\n",
       " 'monast',\n",
       " 'deception',\n",
       " 'importuning',\n",
       " 'beak',\n",
       " 'disesteem',\n",
       " 'vanengelsdorp',\n",
       " 'laney',\n",
       " 'teitz',\n",
       " 'cuerda',\n",
       " 'danielgcolina',\n",
       " 'arcata',\n",
       " 'diesmal',\n",
       " 'apteligent',\n",
       " 'purposeful',\n",
       " 'scheduling',\n",
       " 'played',\n",
       " 'lymphomyosot',\n",
       " 'hobbling',\n",
       " 'aulas',\n",
       " 'humane',\n",
       " 'steingart',\n",
       " 'ankylose',\n",
       " 'nuance',\n",
       " 'kalergi',\n",
       " 'pazira',\n",
       " 'volkswirtschaften',\n",
       " 'arisen',\n",
       " 'alpharetta',\n",
       " 'acct',\n",
       " 'igh',\n",
       " 'captive',\n",
       " 'geographically',\n",
       " 'higkeiten',\n",
       " 'toughest',\n",
       " 'titty',\n",
       " 'validity',\n",
       " 'throbby',\n",
       " 'happer',\n",
       " 'studious',\n",
       " 'wippte',\n",
       " 'wzpqcoaajqvz',\n",
       " 'rgern',\n",
       " 'lessee',\n",
       " 'sluggishness',\n",
       " 'steadfast',\n",
       " 'serion',\n",
       " 'exponentially',\n",
       " 'fister',\n",
       " 'sigourney',\n",
       " 'empuje',\n",
       " 'viceland',\n",
       " 'hyster',\n",
       " 'elkayam',\n",
       " 'bedbedbedbedbed',\n",
       " 'wii',\n",
       " 'parral',\n",
       " 'shkolnik',\n",
       " 'backus',\n",
       " 'thud',\n",
       " 'isler',\n",
       " 'younis',\n",
       " 'mantello',\n",
       " 'zweizimmerwohnung',\n",
       " 'midlife',\n",
       " 'yamiche',\n",
       " 'struyk',\n",
       " 'retract',\n",
       " 'plainer',\n",
       " 'hauler',\n",
       " 'pathophysiological',\n",
       " 'detectably',\n",
       " 'arribismo',\n",
       " 'neuschwabenland',\n",
       " 'pharmaceutic',\n",
       " 'lat',\n",
       " 'shani',\n",
       " 'dionysian',\n",
       " 'myrdal',\n",
       " 'ap',\n",
       " 'contra',\n",
       " 'cartel',\n",
       " 'lww',\n",
       " 'kval',\n",
       " 'mineralsestimated',\n",
       " 'suffuse',\n",
       " 'islander',\n",
       " 'badda',\n",
       " 'expository',\n",
       " 'spaceplane',\n",
       " 'showcases',\n",
       " 'psychocandy',\n",
       " 'brytyjskiego',\n",
       " 'nonconditional',\n",
       " 'perring',\n",
       " 'sunnyvale',\n",
       " 'seaborn',\n",
       " 'columpio',\n",
       " 'petco',\n",
       " 'fiend',\n",
       " 'capitalistic',\n",
       " 'herdener',\n",
       " 'pom',\n",
       " 'progressives',\n",
       " 'ruedo',\n",
       " 'reckitt',\n",
       " 'sportsmanship',\n",
       " 'falsifica',\n",
       " 'guerami',\n",
       " 'inozemtseva',\n",
       " 'bowne',\n",
       " 'articulation',\n",
       " 'locklear',\n",
       " 'thursday',\n",
       " 'gainsay',\n",
       " 'verte',\n",
       " 'motherless',\n",
       " 'filibuster',\n",
       " 'pritha',\n",
       " 'puli',\n",
       " 'endearing',\n",
       " 'propranolol',\n",
       " 'somtime',\n",
       " 'violating',\n",
       " 'harrp',\n",
       " 'reimplante',\n",
       " 'kumandal',\n",
       " 'agrarian',\n",
       " 'armour',\n",
       " 'corroborate',\n",
       " 'peevish',\n",
       " 'standingwithstandingrock',\n",
       " 'papkin',\n",
       " 'pta',\n",
       " 'palabras',\n",
       " 'stretches',\n",
       " 'anguera',\n",
       " 'grushevsky',\n",
       " 'true',\n",
       " 'mattdelpiano',\n",
       " 'invigilate',\n",
       " 'silvesternacht',\n",
       " 'usw',\n",
       " 'quintabe',\n",
       " 'redflag',\n",
       " 'unencrypted',\n",
       " 'strategy',\n",
       " 'ismaily',\n",
       " 'membres',\n",
       " 'longggg',\n",
       " 'taha',\n",
       " 'schuldensuehner',\n",
       " 'standard',\n",
       " 'qwz',\n",
       " 'lorry',\n",
       " 'sel',\n",
       " 'obergefell',\n",
       " 'balfour',\n",
       " 'rabbishmuley',\n",
       " 'obliga',\n",
       " 'hairdresser',\n",
       " 'zeferino',\n",
       " 'grushevskogo',\n",
       " 'organisierte',\n",
       " 'rastrelli',\n",
       " 'chiron',\n",
       " 'weintraub',\n",
       " 'mendacium',\n",
       " 'kofi',\n",
       " 'amol',\n",
       " 'significantly',\n",
       " 'dobbin',\n",
       " 'phyllida',\n",
       " 'underwent',\n",
       " 'glichst',\n",
       " 'secrete',\n",
       " 'seelig',\n",
       " 'campa',\n",
       " 'gwinn',\n",
       " 'connallys',\n",
       " 'dengler',\n",
       " 'alanlar',\n",
       " 'mccaw',\n",
       " 'congr',\n",
       " 'foole',\n",
       " 'interm',\n",
       " 'cellulose',\n",
       " 'jmi',\n",
       " 'dethick',\n",
       " ...}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a990e0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['wordCount'] = data['text'].str.split().str.len() # Populating work count per news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c4ee0c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = len(words) # Number of distinct words in news \n",
    "tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
    "tokenizer.fit_on_texts(data['text'].values)\n",
    "X = tokenizer.texts_to_sequences(data['text'].values)\n",
    "#X_test = tokenizer.texts_to_sequences(testData['comment_text'].values)\n",
    "X = pad_sequences(X)\n",
    "#X_test = pad_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "74675d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    0,     0,     0, ..., 13955, 25504,  1248],\n",
       "       [    0,     0,     0, ...,  1682,   945,  7230],\n",
       "       [    0,     0,     0, ...,   256,  1508,  6413],\n",
       "       ...,\n",
       "       [    0,     0,     0, ...,  3416,  2865,   611],\n",
       "       [    0,     0,     0, ...,  2256,  1388,  2804],\n",
       "       [    0,     0,     0, ..., 14365,  1818,  1714]], dtype=int32)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "543cdfbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 10578, 128)        16590208  \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 10578, 60)         45360     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                3050      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 16,638,669\n",
      "Trainable params: 16,638,669\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "maxlen = max(data['wordCount']) # max number of words per news   \n",
    "embed_dim = 128\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=max_features, output_dim=embed_dim, \n",
    "                              input_length=maxlen),\n",
    "    LSTM(60, return_sequences=True),\n",
    "    GlobalMaxPool1D(),\n",
    "    Dropout(0.1),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(1, activation='sigmoid')])    # only 2 value in each labels\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# using binary crossentropy because each labels or the features only have 2 value, 0 or 1\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6f0e617c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data[['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3721378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 85/163 [==============>...............] - ETA: 14:26 - loss: 0.5585 - accuracy: 0.7425"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "model.fit(X, Y, epochs = 10, batch_size=batch_size, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027e787b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
